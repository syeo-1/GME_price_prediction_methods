{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>RSI</th>\n",
       "      <th>SMA</th>\n",
       "      <th>LMA</th>\n",
       "      <th>ADX</th>\n",
       "      <th>up</th>\n",
       "      <th>Score</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>49.770000</td>\n",
       "      <td>51.189999</td>\n",
       "      <td>44.560001</td>\n",
       "      <td>45.939999</td>\n",
       "      <td>45.939999</td>\n",
       "      <td>9186800.0</td>\n",
       "      <td>45.962590</td>\n",
       "      <td>110.887913</td>\n",
       "      <td>78.886475</td>\n",
       "      <td>26.642816</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.173827</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>49.752222</td>\n",
       "      <td>51.157777</td>\n",
       "      <td>44.505695</td>\n",
       "      <td>45.867082</td>\n",
       "      <td>45.867082</td>\n",
       "      <td>9186800.0</td>\n",
       "      <td>45.953698</td>\n",
       "      <td>110.590784</td>\n",
       "      <td>78.899723</td>\n",
       "      <td>26.625878</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.173827</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>49.734445</td>\n",
       "      <td>51.125555</td>\n",
       "      <td>44.451390</td>\n",
       "      <td>45.794166</td>\n",
       "      <td>45.794166</td>\n",
       "      <td>9186800.0</td>\n",
       "      <td>45.944800</td>\n",
       "      <td>110.295705</td>\n",
       "      <td>78.912937</td>\n",
       "      <td>26.608974</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.173827</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>49.716667</td>\n",
       "      <td>51.093332</td>\n",
       "      <td>44.397084</td>\n",
       "      <td>45.721249</td>\n",
       "      <td>45.721249</td>\n",
       "      <td>9186800.0</td>\n",
       "      <td>45.935898</td>\n",
       "      <td>110.002673</td>\n",
       "      <td>78.926115</td>\n",
       "      <td>26.592103</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.173827</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>49.698889</td>\n",
       "      <td>51.061110</td>\n",
       "      <td>44.342779</td>\n",
       "      <td>45.648332</td>\n",
       "      <td>45.648332</td>\n",
       "      <td>9186800.0</td>\n",
       "      <td>45.926990</td>\n",
       "      <td>109.711690</td>\n",
       "      <td>78.939260</td>\n",
       "      <td>26.575264</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.173827</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close  \\\n",
       "0  2021-02-17  49.770000  51.189999  44.560001  45.939999  45.939999   \n",
       "1  2021-02-17  49.752222  51.157777  44.505695  45.867082  45.867082   \n",
       "2  2021-02-17  49.734445  51.125555  44.451390  45.794166  45.794166   \n",
       "3  2021-02-17  49.716667  51.093332  44.397084  45.721249  45.721249   \n",
       "4  2021-02-17  49.698889  51.061110  44.342779  45.648332  45.648332   \n",
       "\n",
       "      Volume        RSI         SMA        LMA        ADX  up     Score  \\\n",
       "0  9186800.0  45.962590  110.887913  78.886475  26.642816   0 -0.173827   \n",
       "1  9186800.0  45.953698  110.590784  78.899723  26.625878   0 -0.173827   \n",
       "2  9186800.0  45.944800  110.295705  78.912937  26.608974   0 -0.173827   \n",
       "3  9186800.0  45.935898  110.002673  78.926115  26.592103   0 -0.173827   \n",
       "4  9186800.0  45.926990  109.711690  78.939260  26.575264   0 -0.173827   \n",
       "\n",
       "   Sentiment  \n",
       "0         -1  \n",
       "1         -1  \n",
       "2         -1  \n",
       "3         -1  \n",
       "4         -1  "
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load up the augmented processed GME data\n",
    "processed_gme_data = pd.read_csv('GME_augmented_processed.csv')\n",
    "processed_gme_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing to do is to process the data for the LSTM. We'll have to create windows of data to feed into the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need 'lag obeservations': https://machinelearningmastery.com/how-to-use-the-timeseriesgenerator-for-time-series-forecasting-in-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "<keras.preprocessing.sequence.TimeseriesGenerator object at 0x156e9c6a0>\n",
      "[[1 2]] => [3]\n",
      "[[2 3]] => [4]\n",
      "[[3 4]] => [5]\n",
      "[[4 5]] => [6]\n",
      "[[5 6]] => [7]\n",
      "[[6 7]] => [8]\n",
      "[[7 8]] => [9]\n",
      "[[8 9]] => [10]\n"
     ]
    }
   ],
   "source": [
    "# dummy example\n",
    "series = np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "n_input = 2\n",
    "generator = TimeseriesGenerator(series, series, length=n_input, batch_size=1)\n",
    "print(len(generator))\n",
    "# for i in range(len(generator)):\n",
    "print(generator) \n",
    "for i in range(len(generator)):\n",
    "    x, y = generator[i]\n",
    "    print('%s => %s' % (x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109.0\n",
      "5493\n"
     ]
    }
   ],
   "source": [
    "# data is for 109 days\n",
    "print(len(processed_gme_data)/72)\n",
    "\n",
    "# get the split point\n",
    "split_point = int(len(processed_gme_data)*0.7)\n",
    "print(split_point)\n",
    "\n",
    "# create a list of start of day indices to find the closest start of day index\n",
    "start_of_day_indices = [i for i in range(0, len(processed_gme_data), 72)]\n",
    "\n",
    "# find the start of day index that's closest to the split point\n",
    "min_dist = math.inf\n",
    "split_index = None\n",
    "for start_of_day_index in start_of_day_indices:\n",
    "    if abs(split_point-start_of_day_index) < min_dist:\n",
    "        min_dist = abs(split_point-start_of_day_index)\n",
    "        split_index = start_of_day_index\n",
    "# print(f'{split_index} represents day {index_to_use/72}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, training data will be using data from all days up to the 76th day (exclusive). In other words, training data uses 75 \"full\" days worth of data. Testing will use the rest of the data starting from the 76th day and onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a window size for the length parameter (to use for TimeseriesGenerator later)\n",
    "window_size = 2\n",
    "\n",
    "# separate the data to training and testing (approximately 70/30)\n",
    "training = processed_gme_data[:split_index]\n",
    "# offset by window_size since time series training will use input of window_size rows with output of the first row\n",
    "testing = processed_gme_data[split_index - window_size:]\n",
    "\n",
    "# separate each data group into data and labels\n",
    "training_data = training.loc[:, 'Open':'up']\n",
    "# training_data = training.loc[:, 'Open':'ADX']\n",
    "# training_labels = training.loc[:, 'up']\n",
    "\n",
    "testing_data = testing.loc[:, 'Open':'up']\n",
    "# testing_data = testing.loc[:, 'Open':'ADX']\n",
    "# testing_labels = testing.loc[:, 'up']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>RSI</th>\n",
       "      <th>SMA</th>\n",
       "      <th>LMA</th>\n",
       "      <th>ADX</th>\n",
       "      <th>up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49.770000</td>\n",
       "      <td>51.189999</td>\n",
       "      <td>44.560001</td>\n",
       "      <td>45.939999</td>\n",
       "      <td>45.939999</td>\n",
       "      <td>9186800.0</td>\n",
       "      <td>45.962590</td>\n",
       "      <td>110.887913</td>\n",
       "      <td>78.886475</td>\n",
       "      <td>26.642816</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49.752222</td>\n",
       "      <td>51.157777</td>\n",
       "      <td>44.505695</td>\n",
       "      <td>45.867082</td>\n",
       "      <td>45.867082</td>\n",
       "      <td>9186800.0</td>\n",
       "      <td>45.953698</td>\n",
       "      <td>110.590784</td>\n",
       "      <td>78.899723</td>\n",
       "      <td>26.625878</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49.734445</td>\n",
       "      <td>51.125555</td>\n",
       "      <td>44.451390</td>\n",
       "      <td>45.794166</td>\n",
       "      <td>45.794166</td>\n",
       "      <td>9186800.0</td>\n",
       "      <td>45.944800</td>\n",
       "      <td>110.295705</td>\n",
       "      <td>78.912937</td>\n",
       "      <td>26.608974</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49.716667</td>\n",
       "      <td>51.093332</td>\n",
       "      <td>44.397084</td>\n",
       "      <td>45.721249</td>\n",
       "      <td>45.721249</td>\n",
       "      <td>9186800.0</td>\n",
       "      <td>45.935898</td>\n",
       "      <td>110.002673</td>\n",
       "      <td>78.926115</td>\n",
       "      <td>26.592103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.698889</td>\n",
       "      <td>51.061110</td>\n",
       "      <td>44.342779</td>\n",
       "      <td>45.648332</td>\n",
       "      <td>45.648332</td>\n",
       "      <td>9186800.0</td>\n",
       "      <td>45.926990</td>\n",
       "      <td>109.711690</td>\n",
       "      <td>78.939260</td>\n",
       "      <td>26.575264</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Open       High        Low      Close  Adj Close     Volume  \\\n",
       "0  49.770000  51.189999  44.560001  45.939999  45.939999  9186800.0   \n",
       "1  49.752222  51.157777  44.505695  45.867082  45.867082  9186800.0   \n",
       "2  49.734445  51.125555  44.451390  45.794166  45.794166  9186800.0   \n",
       "3  49.716667  51.093332  44.397084  45.721249  45.721249  9186800.0   \n",
       "4  49.698889  51.061110  44.342779  45.648332  45.648332  9186800.0   \n",
       "\n",
       "         RSI         SMA        LMA        ADX  up  \n",
       "0  45.962590  110.887913  78.886475  26.642816   0  \n",
       "1  45.953698  110.590784  78.899723  26.625878   0  \n",
       "2  45.944800  110.295705  78.912937  26.608974   0  \n",
       "3  45.935898  110.002673  78.926115  26.592103   0  \n",
       "4  45.926990  109.711690  78.939260  26.575264   0  "
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize training/testing data using standardscaler\n",
    "# this also converts the data into numpy arrays (necessary for TimeseriesGenerator)\n",
    "data_scaler = StandardScaler()\n",
    "normalized_training_data = data_scaler.fit_transform(training_data)\n",
    "# training_data_scaler = StandardScaler()\n",
    "# training_data_scaler = training_data_scaler.fit(training_data)\n",
    "# normalized_training_data = training_data_scaler.transform(training_data)\n",
    "# normalized_training_data\n",
    "\n",
    "# testing_data_scaler = StandardScaler()\n",
    "# testing_data_scaler = testing_data_scaler.fit(testing_data)\n",
    "# normalized_testing_data = testing_data_scaler.transform(testing_data)\n",
    "normalized_testing_data = data_scaler.transform(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.97402153 -0.97402153 -0.97402153 ...  1.02667135  1.02667135\n",
      "  1.02667135]\n",
      "[1.02667135 1.02667135 1.02667135 ... 1.02667135 1.02667135 1.02667135]\n"
     ]
    }
   ],
   "source": [
    "# identify the label columns\n",
    "normalized_training_labels = normalized_training_data[:, 10]\n",
    "normalized_testing_labels = normalized_testing_data[:, 10]\n",
    "print(normalized_training_labels)\n",
    "print(normalized_testing_labels)\n",
    "# training_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# testing_ts_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(normalized_testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dataframe slices to numpy arrays for the timeseries generator\n",
    "# training_data = np.array(training_data)\n",
    "# training_labels = np.array(training_labels)\n",
    "# testing_data = np.array(testing_data)\n",
    "# testing_labels = np.array(testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create timeseries generators for training and testing data/labels\n",
    "training_ts_generator = TimeseriesGenerator(\n",
    "    data=normalized_training_data,\n",
    "    targets=normalized_training_labels,\n",
    "#     targets=training_labels,\n",
    "    length=window_size,\n",
    "    batch_size=1\n",
    ")\n",
    "\n",
    "testing_ts_generator = TimeseriesGenerator(\n",
    "    data=normalized_testing_data,\n",
    "    targets=normalized_testing_labels,\n",
    "#     targets=testing_labels,\n",
    "    length=window_size,\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_gme_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-2.37120045 -2.40507799 -2.3988217  -2.45805618 -2.45805618\n",
      "   -0.4053415  -1.059327   -1.01771832 -2.04087564  0.81276943\n",
      "   -0.97402153]\n",
      "  [-2.37154838 -2.40565526 -2.39996389 -2.45948248 -2.45948248\n",
      "   -0.4053415  -1.06037428 -1.02443606 -2.04048903  0.81077442\n",
      "   -0.97402153]]] => [-0.97402153]\n"
     ]
    }
   ],
   "source": [
    "# just an example to see what output is\n",
    "for i in range(len(training_ts_generator)):\n",
    "    x, y = training_ts_generator[i]\n",
    "    print('%s => %s' % (x, y))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1.70303493  1.72150508  2.02598938  2.10332388  2.10332388\n",
      "   -0.6397665   1.3803383   1.43456503  1.17756286  1.3348354\n",
      "    1.02667135]\n",
      "  [ 1.70357314  1.72573509  2.02874408  2.11192245  2.11192245\n",
      "   -0.6397665   1.38802248  1.43679133  1.17929748  1.33863748\n",
      "    1.02667135]]] => [1.02667135]\n"
     ]
    }
   ],
   "source": [
    "# just an example to see what output is\n",
    "for i in range(len(testing_ts_generator)):\n",
    "    x, y = testing_ts_generator[i]\n",
    "    print('%s => %s' % (x, y))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized_testing_data.shape\n",
    "# training_ts_generator.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_44 (LSTM)               (None, 2, 64)             19456     \n",
      "_________________________________________________________________\n",
      "lstm_45 (LSTM)               (None, 96)                61824     \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 97        \n",
      "=================================================================\n",
      "Total params: 81,377\n",
      "Trainable params: 81,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define an LSTM for the normalized training data\n",
    "training_model = Sequential()\n",
    "# input_shape for each data input is window_size x number of features (column) in training_data\n",
    "training_model.add(LSTM(64, activation='sigmoid', input_shape=(window_size, 11), return_sequences=True))\n",
    "training_model.add(LSTM(96, activation='sigmoid', return_sequences=False))\n",
    "training_model.add(Dropout(0.2))\n",
    "\n",
    "# output either standardized 0 or 1\n",
    "training_model.add(Dense(1))\n",
    "\n",
    "training_model.compile(optimizer='SGD', loss='mse')\n",
    "training_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5470/5470 [==============================] - 29s 4ms/step - loss: 0.9064 - val_loss: 0.0475\n",
      "Epoch 2/10\n",
      "5470/5470 [==============================] - 22s 4ms/step - loss: 0.0938 - val_loss: 0.0303\n",
      "Epoch 3/10\n",
      "5470/5470 [==============================] - 30s 5ms/step - loss: 0.0684 - val_loss: 0.0352\n",
      "Epoch 4/10\n",
      "5470/5470 [==============================] - 28s 5ms/step - loss: 0.0616 - val_loss: 0.0295\n",
      "Epoch 5/10\n",
      "5470/5470 [==============================] - 31s 6ms/step - loss: 0.0563 - val_loss: 0.0383\n",
      "Epoch 6/10\n",
      "5470/5470 [==============================] - 29s 5ms/step - loss: 0.0532 - val_loss: 0.0302\n",
      "Epoch 7/10\n",
      "5470/5470 [==============================] - 29s 5ms/step - loss: 0.0514 - val_loss: 0.0312\n",
      "Epoch 8/10\n",
      "5470/5470 [==============================] - 29s 5ms/step - loss: 0.0541 - val_loss: 0.0300\n",
      "Epoch 9/10\n",
      "5470/5470 [==============================] - 21s 4ms/step - loss: 0.0413 - val_loss: 0.0291\n",
      "Epoch 10/10\n",
      "5470/5470 [==============================] - 30s 6ms/step - loss: 0.0463 - val_loss: 0.0293\n",
      "CPU times: user 6min 38s, sys: 34.8 s, total: 7min 13s\n",
      "Wall time: 5min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history_train = training_model.fit(training_ts_generator, validation_data=testing_ts_generator, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.5626396536827087,\n",
       "  0.07855729758739471,\n",
       "  0.062411241233348846,\n",
       "  0.05573398619890213,\n",
       "  0.05248274654150009,\n",
       "  0.05013328045606613,\n",
       "  0.04878585413098335,\n",
       "  0.048257406800985336,\n",
       "  0.04595864564180374,\n",
       "  0.04630189761519432],\n",
       " 'val_loss': [0.04745972156524658,\n",
       "  0.03030472621321678,\n",
       "  0.03520014137029648,\n",
       "  0.02949136309325695,\n",
       "  0.03825923800468445,\n",
       "  0.0301724374294281,\n",
       "  0.03115302324295044,\n",
       "  0.030026188120245934,\n",
       "  0.02905491553246975,\n",
       "  0.029309706762433052]}"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_train.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# history_train.history\n",
    "plt.plot(history_train.history['loss'])\n",
    "plt.plot(history_train.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5470/5470 [==============================] - 11s 2ms/step - loss: 0.0304\n",
      "2376/2376 [==============================] - 5s 2ms/step - loss: 0.0293\n"
     ]
    }
   ],
   "source": [
    "training_results = training_model.evaluate(training_ts_generator)\n",
    "testing_results = training_model.evaluate(testing_ts_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results\n",
    "prediction_results = training_model.predict(testing_ts_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0091802 ],\n",
       "       [1.0092525 ],\n",
       "       [1.0091311 ],\n",
       "       ...,\n",
       "       [0.98138934],\n",
       "       [0.9814202 ],\n",
       "       [0.98145086]], dtype=float32)"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0091802 , 1.0091802 , 1.0091802 , ..., 1.0091802 , 1.0091802 ,\n",
       "        1.0091802 ],\n",
       "       [1.0092525 , 1.0092525 , 1.0092525 , ..., 1.0092525 , 1.0092525 ,\n",
       "        1.0092525 ],\n",
       "       [1.0091311 , 1.0091311 , 1.0091311 , ..., 1.0091311 , 1.0091311 ,\n",
       "        1.0091311 ],\n",
       "       ...,\n",
       "       [0.98138934, 0.98138934, 0.98138934, ..., 0.98138934, 0.98138934,\n",
       "        0.98138934],\n",
       "       [0.9814202 , 0.9814202 , 0.9814202 , ..., 0.9814202 , 0.9814202 ,\n",
       "        0.9814202 ],\n",
       "       [0.98145086, 0.98145086, 0.98145086, ..., 0.98145086, 0.98145086,\n",
       "        0.98145086]], dtype=float32)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correctly_shaped_prediction_results = np.repeat(prediction_results, 11, axis=-1)\n",
    "correctly_shaped_prediction_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_transform_results = data_scaler.inverse_transform(correctly_shaped_prediction_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_results = inverse_transform_results[:, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(binary_results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_testing_labels = []\n",
    "for label in binary_results:\n",
    "    if label > 0.9:\n",
    "        predicted_testing_labels.append(1)\n",
    "    else:\n",
    "        predicted_testing_labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_testing_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_testing_labels = list(testing_data['up'])\n",
    "# actual_testing_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2368\n",
      "2378\n",
      "0.9957947855340622\n"
     ]
    }
   ],
   "source": [
    "correct_count = 0\n",
    "for predicted_label, actual_label in zip(predicted_testing_labels, actual_testing_labels):\n",
    "    if predicted_label == actual_label:\n",
    "        correct_count += 1\n",
    "print(correct_count)\n",
    "print(len(actual_testing_labels))\n",
    "\n",
    "# print out correct ratio\n",
    "print(correct_count/len(actual_testing_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BELOW USED FOR TESTING. RUN OPTIONALLY (takes excessively long time [4-5 hours])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing different values of time step for accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_24 (LSTM)               (None, 1, 64)             19456     \n",
      "_________________________________________________________________\n",
      "lstm_25 (LSTM)               (None, 96)                61824     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 97        \n",
      "=================================================================\n",
      "Total params: 81,377\n",
      "Trainable params: 81,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "5471/5471 [==============================] - 22s 3ms/step - loss: 1.0090 - val_loss: 0.0892\n",
      "Epoch 2/5\n",
      "5471/5471 [==============================] - 16s 3ms/step - loss: 0.1102 - val_loss: 0.0332\n",
      "Epoch 3/5\n",
      "5471/5471 [==============================] - 17s 3ms/step - loss: 0.0678 - val_loss: 0.0272\n",
      "Epoch 4/5\n",
      "5471/5471 [==============================] - 17s 3ms/step - loss: 0.0643 - val_loss: 0.0277\n",
      "Epoch 5/5\n",
      "5471/5471 [==============================] - 19s 4ms/step - loss: 0.0602 - val_loss: 0.0263\n",
      "5471/5471 [==============================] - 7s 1ms/step - loss: 0.0278\n",
      "2447/2447 [==============================] - 3s 1ms/step - loss: 0.0263\n",
      "2447\n",
      "2448\n",
      "0.9995915032679739\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_26 (LSTM)               (None, 2, 64)             19456     \n",
      "_________________________________________________________________\n",
      "lstm_27 (LSTM)               (None, 96)                61824     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 97        \n",
      "=================================================================\n",
      "Total params: 81,377\n",
      "Trainable params: 81,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 26s 4ms/step - loss: 0.9554 - val_loss: 0.0399\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 24s 4ms/step - loss: 0.0966 - val_loss: 0.0358\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 24s 4ms/step - loss: 0.0700 - val_loss: 0.0305\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0646 - val_loss: 0.0324\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 0.0526 - val_loss: 0.0316\n",
      "5470/5470 [==============================] - 7s 1ms/step - loss: 0.0308\n",
      "2446/2446 [==============================] - 3s 1ms/step - loss: 0.0316\n",
      "2438\n",
      "2448\n",
      "0.9959150326797386\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_28 (LSTM)               (None, 3, 64)             19456     \n",
      "_________________________________________________________________\n",
      "lstm_29 (LSTM)               (None, 96)                61824     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 97        \n",
      "=================================================================\n",
      "Total params: 81,377\n",
      "Trainable params: 81,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "5469/5469 [==============================] - 29s 4ms/step - loss: 0.8914 - val_loss: 0.0732\n",
      "Epoch 2/5\n",
      "5469/5469 [==============================] - 22s 4ms/step - loss: 0.0853 - val_loss: 0.0358\n",
      "Epoch 3/5\n",
      "5469/5469 [==============================] - 25s 4ms/step - loss: 0.0715 - val_loss: 0.0365\n",
      "Epoch 4/5\n",
      "5469/5469 [==============================] - 24s 4ms/step - loss: 0.0605 - val_loss: 0.0371\n",
      "Epoch 5/5\n",
      "5469/5469 [==============================] - 26s 5ms/step - loss: 0.0525 - val_loss: 0.0323\n",
      "5469/5469 [==============================] - 8s 1ms/step - loss: 0.0310\n",
      "2445/2445 [==============================] - 4s 1ms/step - loss: 0.0323\n",
      "2429\n",
      "2448\n",
      "0.9922385620915033\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_30 (LSTM)               (None, 4, 64)             19456     \n",
      "_________________________________________________________________\n",
      "lstm_31 (LSTM)               (None, 96)                61824     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 97        \n",
      "=================================================================\n",
      "Total params: 81,377\n",
      "Trainable params: 81,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "5468/5468 [==============================] - 31s 5ms/step - loss: 0.8841 - val_loss: 0.0627\n",
      "Epoch 2/5\n",
      "5468/5468 [==============================] - 28s 5ms/step - loss: 0.0748 - val_loss: 0.0346\n",
      "Epoch 3/5\n",
      "5468/5468 [==============================] - 26s 5ms/step - loss: 0.0687 - val_loss: 0.0332\n",
      "Epoch 4/5\n",
      "5468/5468 [==============================] - 25s 5ms/step - loss: 0.0574 - val_loss: 0.0385\n",
      "Epoch 5/5\n",
      "5468/5468 [==============================] - 25s 5ms/step - loss: 0.0605 - val_loss: 0.0336\n",
      "5468/5468 [==============================] - 8s 2ms/step - loss: 0.0347\n",
      "2444/2444 [==============================] - 4s 2ms/step - loss: 0.0336\n",
      "2413\n",
      "2448\n",
      "0.985702614379085\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_32 (LSTM)               (None, 5, 64)             19456     \n",
      "_________________________________________________________________\n",
      "lstm_33 (LSTM)               (None, 96)                61824     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 97        \n",
      "=================================================================\n",
      "Total params: 81,377\n",
      "Trainable params: 81,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "5467/5467 [==============================] - 33s 5ms/step - loss: 0.8273 - val_loss: 0.0382\n",
      "Epoch 2/5\n",
      "5467/5467 [==============================] - 29s 5ms/step - loss: 0.0706 - val_loss: 0.0610\n",
      "Epoch 3/5\n",
      "5467/5467 [==============================] - 31s 6ms/step - loss: 0.0619 - val_loss: 0.0318\n",
      "Epoch 4/5\n",
      "5467/5467 [==============================] - 29s 5ms/step - loss: 0.0617 - val_loss: 0.0343\n",
      "Epoch 5/5\n",
      "5467/5467 [==============================] - 31s 6ms/step - loss: 0.0531 - val_loss: 0.0316\n",
      "5467/5467 [==============================] - 11s 2ms/step - loss: 0.0322\n",
      "2443/2443 [==============================] - 5s 2ms/step - loss: 0.0316\n",
      "2395\n",
      "2448\n",
      "0.9783496732026143\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_34 (LSTM)               (None, 6, 64)             19456     \n",
      "_________________________________________________________________\n",
      "lstm_35 (LSTM)               (None, 96)                61824     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 97        \n",
      "=================================================================\n",
      "Total params: 81,377\n",
      "Trainable params: 81,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5466/5466 [==============================] - 48s 8ms/step - loss: 0.7950 - val_loss: 0.0394\n",
      "Epoch 2/5\n",
      "5466/5466 [==============================] - 50s 9ms/step - loss: 0.0836 - val_loss: 0.0346\n",
      "Epoch 3/5\n",
      "5466/5466 [==============================] - 69s 13ms/step - loss: 0.0572 - val_loss: 0.0798\n",
      "Epoch 4/5\n",
      "5466/5466 [==============================] - 51s 9ms/step - loss: 0.0553 - val_loss: 0.0327\n",
      "Epoch 5/5\n",
      "5466/5466 [==============================] - 50s 9ms/step - loss: 0.0535 - val_loss: 0.0323\n",
      "5466/5466 [==============================] - 14s 3ms/step - loss: 0.0329\n",
      "2442/2442 [==============================] - 6s 2ms/step - loss: 0.0323\n",
      "2378\n",
      "2448\n",
      "0.9714052287581699\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_36 (LSTM)               (None, 7, 64)             19456     \n",
      "_________________________________________________________________\n",
      "lstm_37 (LSTM)               (None, 96)                61824     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 97        \n",
      "=================================================================\n",
      "Total params: 81,377\n",
      "Trainable params: 81,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "5465/5465 [==============================] - 64s 10ms/step - loss: 0.7827 - val_loss: 0.0361\n",
      "Epoch 2/5\n",
      "5465/5465 [==============================] - 60s 11ms/step - loss: 0.0838 - val_loss: 0.0389\n",
      "Epoch 3/5\n",
      "5465/5465 [==============================] - 55s 10ms/step - loss: 0.0553 - val_loss: 0.0338\n",
      "Epoch 4/5\n",
      "5465/5465 [==============================] - 58s 11ms/step - loss: 0.0552 - val_loss: 0.0345\n",
      "Epoch 5/5\n",
      "5465/5465 [==============================] - 62s 11ms/step - loss: 0.0505 - val_loss: 0.0325\n",
      "5465/5465 [==============================] - 16s 3ms/step - loss: 0.0337\n",
      "2441/2441 [==============================] - 8s 3ms/step - loss: 0.0325\n",
      "2369\n",
      "2448\n",
      "0.9677287581699346\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_38 (LSTM)               (None, 8, 64)             19456     \n",
      "_________________________________________________________________\n",
      "lstm_39 (LSTM)               (None, 96)                61824     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 97        \n",
      "=================================================================\n",
      "Total params: 81,377\n",
      "Trainable params: 81,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "5464/5464 [==============================] - 70s 11ms/step - loss: 0.8548 - val_loss: 0.0403\n",
      "Epoch 2/5\n",
      "5464/5464 [==============================] - 56s 10ms/step - loss: 0.0714 - val_loss: 0.0340\n",
      "Epoch 3/5\n",
      "5464/5464 [==============================] - 63s 12ms/step - loss: 0.0704 - val_loss: 0.0426\n",
      "Epoch 4/5\n",
      "5464/5464 [==============================] - 61s 11ms/step - loss: 0.0615 - val_loss: 0.0452\n",
      "Epoch 5/5\n",
      "5464/5464 [==============================] - 41s 8ms/step - loss: 0.0561 - val_loss: 0.0328\n",
      "5464/5464 [==============================] - 18s 3ms/step - loss: 0.0335\n",
      "2440/2440 [==============================] - 8s 3ms/step - loss: 0.0328\n",
      "2346\n",
      "2448\n",
      "0.9583333333333334\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_40 (LSTM)               (None, 9, 64)             19456     \n",
      "_________________________________________________________________\n",
      "lstm_41 (LSTM)               (None, 96)                61824     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 97        \n",
      "=================================================================\n",
      "Total params: 81,377\n",
      "Trainable params: 81,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "5463/5463 [==============================] - 76s 12ms/step - loss: 0.7047 - val_loss: 0.0376\n",
      "Epoch 2/5\n",
      "5463/5463 [==============================] - 64s 12ms/step - loss: 0.0797 - val_loss: 0.0421\n",
      "Epoch 3/5\n",
      "5463/5463 [==============================] - 65s 12ms/step - loss: 0.0666 - val_loss: 0.0419\n",
      "Epoch 4/5\n",
      "5463/5463 [==============================] - 46s 8ms/step - loss: 0.0531 - val_loss: 0.0355\n",
      "Epoch 5/5\n",
      "5463/5463 [==============================] - 58s 11ms/step - loss: 0.0621 - val_loss: 0.0434\n",
      "5463/5463 [==============================] - 11s 2ms/step - loss: 0.0432\n",
      "2439/2439 [==============================] - 5s 2ms/step - loss: 0.0434\n",
      "2279\n",
      "2448\n",
      "0.9309640522875817\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_42 (LSTM)               (None, 10, 64)            19456     \n",
      "_________________________________________________________________\n",
      "lstm_43 (LSTM)               (None, 96)                61824     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 97        \n",
      "=================================================================\n",
      "Total params: 81,377\n",
      "Trainable params: 81,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "5462/5462 [==============================] - 74s 12ms/step - loss: 0.7461 - val_loss: 0.0390\n",
      "Epoch 2/5\n",
      "5462/5462 [==============================] - 64s 12ms/step - loss: 0.0687 - val_loss: 0.0353\n",
      "Epoch 3/5\n",
      "5462/5462 [==============================] - 62s 11ms/step - loss: 0.0596 - val_loss: 0.0442\n",
      "Epoch 4/5\n",
      "5462/5462 [==============================] - 58s 11ms/step - loss: 0.0562 - val_loss: 0.0495\n",
      "Epoch 5/5\n",
      "5462/5462 [==============================] - 65s 12ms/step - loss: 0.0503 - val_loss: 0.0329\n",
      "5462/5462 [==============================] - 16s 3ms/step - loss: 0.0340: 1s -\n",
      "2438/2438 [==============================] - 7s 3ms/step - loss: 0.0329\n",
      "2318\n",
      "2448\n",
      "0.9468954248366013\n"
     ]
    }
   ],
   "source": [
    "window_accuracies = []\n",
    "for window in range (1,11):\n",
    "    training_ts_generator = TimeseriesGenerator(\n",
    "        data=normalized_training_data,\n",
    "        targets=normalized_training_labels,\n",
    "    #     targets=training_labels,\n",
    "        length=window,\n",
    "        batch_size=1\n",
    "    )\n",
    "\n",
    "    testing_ts_generator = TimeseriesGenerator(\n",
    "        data=normalized_testing_data,\n",
    "        targets=normalized_testing_labels,\n",
    "    #     targets=testing_labels,\n",
    "        length=window,\n",
    "        batch_size=1\n",
    "    ) \n",
    "    training_model = Sequential()\n",
    "    # input_shape for each data input is window_size x number of features (column) in training_data\n",
    "    training_model.add(LSTM(64, activation='sigmoid', input_shape=(window, 11), return_sequences=True))\n",
    "    training_model.add(LSTM(96, activation='sigmoid', return_sequences=False))\n",
    "    training_model.add(Dropout(0.2))\n",
    "\n",
    "    # output either standardized 0 or 1\n",
    "    training_model.add(Dense(1))\n",
    "\n",
    "    training_model.compile(optimizer='SGD', loss='mse')\n",
    "    training_model.summary()\n",
    "    \n",
    "    history_train = training_model.fit(training_ts_generator, validation_data=testing_ts_generator, epochs=5)\n",
    "    \n",
    "    training_results = training_model.evaluate(training_ts_generator)\n",
    "    testing_results = training_model.evaluate(testing_ts_generator)\n",
    "    \n",
    "    prediction_results = training_model.predict(testing_ts_generator)\n",
    "    \n",
    "    correctly_shaped_prediction_results = np.repeat(prediction_results, 11, axis=-1)\n",
    "\n",
    "    inverse_transform_results = data_scaler.inverse_transform(correctly_shaped_prediction_results)\n",
    "    \n",
    "    binary_results = inverse_transform_results[:, 10]\n",
    "    \n",
    "    predicted_testing_labels = []\n",
    "    for label in binary_results:\n",
    "        if label > 0.9:\n",
    "            predicted_testing_labels.append(1)\n",
    "        else:\n",
    "            predicted_testing_labels.append(0)\n",
    "            \n",
    "    correct_count = 0\n",
    "    for predicted_label, actual_label in zip(predicted_testing_labels, actual_testing_labels):\n",
    "        if predicted_label == actual_label:\n",
    "            correct_count += 1\n",
    "    print(correct_count)\n",
    "    print(len(actual_testing_labels))\n",
    "\n",
    "    # print out correct ratio\n",
    "    current_accuracy = correct_count/len(actual_testing_labels)\n",
    "    print(current_accuracy)\n",
    "    window_accuracies.append(current_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(window_accuracies)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plot, it appears that the more lagged observations are given, the lower the accuracy becomes. Although there is a shift in trend, based on the amount of time it takes to run the network (about 8 minutes per network with 5 epochs), this will be an area for further improvment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we extend to 72 for the time steps size, the accuracy goes all the way to approximately 50%. Two such networks are saved in the keras_models folder. One represents a network that uses the sentiment data, while the other does not use the sentiment data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9995915032679739,\n",
       " 0.9959150326797386,\n",
       " 0.9922385620915033,\n",
       " 0.985702614379085,\n",
       " 0.9783496732026143,\n",
       " 0.9714052287581699,\n",
       " 0.9677287581699346,\n",
       " 0.9583333333333334,\n",
       " 0.9309640522875817,\n",
       " 0.9468954248366013]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save the model so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./keras_models/lstm_72_sequence_20_epoch/assets\n"
     ]
    }
   ],
   "source": [
    "# training_model.save('./keras_models/lstm_72_sequence_20_epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32, 64, 96, 128]"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_funcs = ['relu', 'sigmoid', 'softmax']\n",
    "node_values = [val for val in range(32, 129, 32)]\n",
    "drop_values = [0.2, 0.3, 0.4, 0.5]\n",
    "node_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# history_train = training_model.fit(training_ts_generator, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_results = training_model.evaluate(training_ts_generator)\n",
    "# testing_results = training_model.evaluate(testing_ts_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.5724188089370728,\n",
       "  0.0920354574918747,\n",
       "  0.07440289109945297,\n",
       "  0.06676856428384781,\n",
       "  0.06256063282489777,\n",
       "  0.0596199706196785,\n",
       "  0.056295670568943024,\n",
       "  0.05643153190612793,\n",
       "  0.0549185648560524,\n",
       "  0.05512009561061859]}"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training_results\n",
    "history_train.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 20s 3ms/step - loss: 0.4397\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0684: \n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0654\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0574\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0541\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 0.0340\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0337\n",
      "relu, 32, 32, 0.2\n",
      "0.033741582185029984\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.3524\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0771\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0767\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0652\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0716\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 0.0343\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0360\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.3342\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.1095\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 22s 4ms/step - loss: 0.0961\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0958\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0908\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 0.0341\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0341\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 20s 3ms/step - loss: 0.4178\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.1125\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 0.1201\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.1060\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 0.1024\n",
      "5470/5470 [==============================] - 10s 2ms/step - loss: 0.0383\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.0413\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 22s 3ms/step - loss: 0.3950\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0507\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0523\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0498\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0485\n",
      "5470/5470 [==============================] - 10s 2ms/step - loss: 0.0364: 0s - loss: 0.\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.0375\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 22s 3ms/step - loss: 0.3506\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0651\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0655\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0563\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0645\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 0.0354\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0359\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 20s 3ms/step - loss: 0.4081\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0660\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0682\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0633\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0706\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 0.0340\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0354\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 20s 3ms/step - loss: 0.4789\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0899\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 0.0853\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0744\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0786\n",
      "5470/5470 [==============================] - 14s 2ms/step - loss: 0.0346\n",
      "2376/2376 [==============================] - 4s 1ms/step - loss: 0.0377\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 20s 3ms/step - loss: 0.3634: 0s\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0505\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0463\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0455: 0s - loss\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0532\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 0.0337\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0365\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 21s 3ms/step - loss: 0.3744\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0495\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 26s 5ms/step - loss: 0.0526\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 28s 5ms/step - loss: 0.0456\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0455\n",
      "5470/5470 [==============================] - 11s 2ms/step - loss: 0.0387\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.0427A\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 21s 3ms/step - loss: 0.3654\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0707:\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 23s 4ms/step - loss: 0.0607: 0s \n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0532\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0608\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 0.0355\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.0349\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 22s 3ms/step - loss: 0.3764\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0774\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0722\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0614\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0641\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0342\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0421\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.3379\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0502\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0529\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0390\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0491\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0380\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0362\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 29s 4ms/step - loss: 0.3650\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0506: 0s -\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0514\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.0421\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0506\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0346\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.0373\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 28s 4ms/step - loss: 0.3862\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0562\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0476:\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0559\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0509\n",
      "5470/5470 [==============================] - 9s 2ms/step - loss: 0.0345\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.0444\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 21s 3ms/step - loss: 0.3798\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0639\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0560\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0668\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.0578\n",
      "5470/5470 [==============================] - 9s 2ms/step - loss: 0.0360\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.0354\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 20s 3ms/step - loss: 0.3407\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0559\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0541\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0673\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0522\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0354\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0357\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.3864\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0739\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0661\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0725\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0654\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0363\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0383\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.3485\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0897\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0866\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0817\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0869\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0416\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0384\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.3875\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.1118\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 14s 3ms/step - loss: 0.1082\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.1117\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 14s 3ms/step - loss: 0.1110\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0376\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0398\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.3218\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0530\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0584\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0591\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0441\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0350\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0471\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.3130\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0605\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0492\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0498\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0554\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0347\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0367\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.3793\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 14s 3ms/step - loss: 0.0742\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0625\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0712\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0678\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0350\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0376\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 21s 3ms/step - loss: 0.4273\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0831\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0705\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0745: \n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 0.0756\n",
      "5470/5470 [==============================] - 13s 1ms/step - loss: 0.0350\n",
      "2376/2376 [==============================] - 4s 1ms/step - loss: 0.0445A: 0\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 21s 3ms/step - loss: 0.3401\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0547\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0450\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0367\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0479\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 0.0351\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0350\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 22s 3ms/step - loss: 0.3545\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0541\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0500\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0474\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0532\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0370\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0359\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 21s 3ms/step - loss: 0.3994\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0755\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.0518\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0573\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 0.0499\n",
      "5470/5470 [==============================] - 11s 2ms/step - loss: 0.0352\n",
      "2376/2376 [==============================] - 4s 1ms/step - loss: 0.0410\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 26s 4ms/step - loss: 0.3834\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.0737\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0655\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0639\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0692\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 0.0363\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.0400\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 21s 3ms/step - loss: 0.3440\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0417\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0447\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0524\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0424\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0458\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 20s 3ms/step - loss: 0.3702\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0568\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0484\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0465\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0460\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 0.0489\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0382\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 20s 3ms/step - loss: 0.3512\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0554\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0530\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0567\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0522\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 0.0349\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.0358\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 22s 3ms/step - loss: 0.4051\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0753\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0683\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0732\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0523\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0359\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0373\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.3651\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0613\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0539\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0586\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0545\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0355\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0346\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 22s 3ms/step - loss: 0.3447\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0887\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0808\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0729\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0728\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0389\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0447\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.3679\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.1000\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0904\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0843\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0866\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0391\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0497\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.3820\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.1201\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.1212\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.1090\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.1010\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0372\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0383\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.2877\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0477\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0521\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0557\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0443\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0344\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0346\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.3284\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0548\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0667\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0513\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0473\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0355A: 0s - loss\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0357\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.3693\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0676\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0705\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0640\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0608\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0369\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0349\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.3758\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0803\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0653\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0713\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0822\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0366\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0375\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.3422: 0s - los\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0531\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0456\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0588\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0428\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0344\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0373\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 20s 3ms/step - loss: 0.3244\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0509\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0502\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0496\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0495\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0343\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0354\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.3580\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0595\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0579\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0513\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0555\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0403\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0371\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 21s 3ms/step - loss: 0.3632\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0664\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0636\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0672\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0610\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0361\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0354\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.3519\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0485\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0473\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0490\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0425\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0359\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0345\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 20s 3ms/step - loss: 0.3744\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0540\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0491\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0417\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0483\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0347\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0360\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.3145\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0523: 0s - loss: 0.0\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0496\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0536\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0451\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0364\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0453\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.3645\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0658\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0669\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0515\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0644\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0358\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0352\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.3264\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0538\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0679\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0623: 0\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0532\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0357\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0355\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.3323\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0737\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0699\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0707\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0673\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0356\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0361\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.3410\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.1176\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.1053\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0960\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0924\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0407\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0405\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.3941\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.1173\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.1054\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.1144\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.1094\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0401A: 1s -  -\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0470\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.3018\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0585\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0532\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0434\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0488\n",
      "5470/5470 [==============================] - 10s 1ms/step - loss: 0.0355: 0s - loss:\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0355\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.3282\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0560\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0670\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0495\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0522\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0446\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0627\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.3440\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0777\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0595\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0731\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0552\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0350\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0361\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 20s 3ms/step - loss: 0.3545\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0801\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0777\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0749\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0762\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0360\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0359\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.3870\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0579\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0432\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0482\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0511\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0455\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0357\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.3323\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0657\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0557\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0564\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0557\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0345\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0391\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5470/5470 [==============================] - 20s 3ms/step - loss: 0.3252\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 22s 4ms/step - loss: 0.0617\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 21s 4ms/step - loss: 0.0666\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0665\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0546\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 0.0540\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.0347\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 22s 3ms/step - loss: 0.3412\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.0639\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.0670\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.0726\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.0619\n",
      "5470/5470 [==============================] - 9s 2ms/step - loss: 0.0391\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.0524A: 0s - l\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 23s 4ms/step - loss: 0.3457\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 0.0471: 0s - lo\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 0.0475\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 0.0422\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 0.0473\n",
      "5470/5470 [==============================] - 9s 2ms/step - loss: 0.0435\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.0445\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 23s 3ms/step - loss: 0.3518\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.0565\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.0515\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.0439\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0529\n",
      "5470/5470 [==============================] - 9s 2ms/step - loss: 0.0350\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.0366\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 23s 3ms/step - loss: 0.3395\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 0.0574\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.0602\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 0.0543\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.0494\n",
      "5470/5470 [==============================] - 10s 2ms/step - loss: 0.0352: 1s - loss: 0.035 - ETA: 1s - loss: 0.\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.0362\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 23s 4ms/step - loss: 0.3679\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 0.0658\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 0.0589: 0s\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 0.0611\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 0.0590\n",
      "5470/5470 [==============================] - 10s 2ms/step - loss: 0.0354: 0s - los\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.0442\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 20s 3ms/step - loss: 0.8359\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0990\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0710\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0702\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0634\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 0.0337\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0312\n",
      "sigmoid, 32, 32, 0.2\n",
      "0.03116992674767971\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 20s 3ms/step - loss: 0.9929: - ETA: 4\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.1322\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0988\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0863\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0782\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 0.0300\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0313\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0498\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.2148\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.1214\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.1153\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.1101\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 0.0336\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0336\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 20s 3ms/step - loss: 1.0686\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.3020\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.1520\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.1247\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.1266\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0316\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0324\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 20s 3ms/step - loss: 0.8484\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0855\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0646\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0638\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0550\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0295\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0294\n",
      "sigmoid, 32, 64, 0.2\n",
      "0.02943655103445053\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 20s 3ms/step - loss: 0.8991\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.1252\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0874\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0830\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0691\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 0.0298\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0298\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 20s 3ms/step - loss: 1.0621\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.1586\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.1019\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0838\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0720\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0312\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0349\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.1104\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.2709\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.1233\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.1009\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0919\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0321\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0322\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 20s 3ms/step - loss: 0.9692\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0980\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0660\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0630\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0532\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0300\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0301\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0550\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.1215\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0797\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0765\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0557\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0304\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0314\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.1366\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.1692\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0920\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0838: 0s - loss: 0.083\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0674\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0326\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0338\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.1392\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.1990\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.1079\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0900\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0935\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0396\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0450\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.9934\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0883\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0631\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0544\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0592\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0312\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0326\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0244: 0s\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.1076\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0754\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0670\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0574\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0297\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0303\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.1313\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.1412\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0893\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0806\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0686\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0340\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0351\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.2185\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.2431\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.1066\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0816\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0757\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0320\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0338\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.8209\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0899\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0720\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0728\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0626\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0337\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0332\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.9185\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.1225\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0922\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0742\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0746\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0342\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0365\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.9762\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.1681\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.1160\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0979\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0972\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0362\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0356\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 21s 3ms/step - loss: 1.0763\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.3029\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.1509: 0s - lo\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.1268\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.1243\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0342\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0351\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.8608\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0823\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0648: 0s - los\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0637\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0608\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0329\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0303\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.9623\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.1101\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0794\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0841\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0689\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0304\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0299\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0718\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.1638\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.1004\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0836\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0799\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0317\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0510\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.1847\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.1260\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0989\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0967\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0411\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0443\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 20s 3ms/step - loss: 0.9496\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0906\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0728\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0740\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0567\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 0.0291\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0292\n",
      "sigmoid, 64, 96, 0.2\n",
      "0.02916168048977852\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 20s 3ms/step - loss: 0.9877\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.1043\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0735\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0599\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0637\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0316\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0324\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0939\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.1406\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0853\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0772\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0676\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0376\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0412\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.1465\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.1933\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.1052\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0876\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0892\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0348\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0338\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.9574\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0841: 0s - loss: 0.\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0686\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0565\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0492\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0291\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0294\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 22s 3ms/step - loss: 1.0651\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.1140\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0748\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0548\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0542\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0464\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0442\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0492\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.1292: 0s - loss\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0808\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0689: 0s - loss: 0.06\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0688\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0303\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0313\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.1404\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.1637\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0978\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0895\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0743\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0359\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0360\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.8354\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0972\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0708\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0607\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0655\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0344\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0366\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.9006\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 23s 4ms/step - loss: 0.1218\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0870\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0811\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0787\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0305\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0317\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.9970\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.1609\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 22s 4ms/step - loss: 0.1115\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0948\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0917\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0300\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0313\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 20s 3ms/step - loss: 0.9995\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.1953\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.1307\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.1119\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.1085\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0337\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0327\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 20s 3ms/step - loss: 0.8590\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0857\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0659\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0553\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0467\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0306\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0302\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.9529\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.1049\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0732\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0723\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0742\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0298\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0300\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.9743\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.1406\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 0.0917\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0783\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0786\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0319\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0321\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 22s 3ms/step - loss: 1.0706\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.1835\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.1143\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0914\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0960\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 0.0296\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.0304\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 27s 4ms/step - loss: 0.9263\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0842\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0639\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0607\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0514\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0329A: 0s - loss: 0.\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0344\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.9505\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.1080\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0821\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0662\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0647\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0330\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0323\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 20s 3ms/step - loss: 1.0411\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.1366\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0909\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0721\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0717\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0304\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0299\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 20s 3ms/step - loss: 1.0823\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.1655\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.1177\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0843\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0833\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 0.0327\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0347\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 22s 3ms/step - loss: 0.9381\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 0.0905\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 0.0605\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 0.0583\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0437\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 0.0762\n",
      "2376/2376 [==============================] - 4s 1ms/step - loss: 0.0740\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 22s 3ms/step - loss: 0.9831\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 21s 4ms/step - loss: 0.0930\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.0728\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.0616\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 0.0562\n",
      "5470/5470 [==============================] - 10s 2ms/step - loss: 0.0331: 0\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.0362\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 23s 4ms/step - loss: 1.0505\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 0.1303\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 0.0766\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 0.0814\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 0.0692\n",
      "5470/5470 [==============================] - 9s 2ms/step - loss: 0.0315\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.0333\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 22s 3ms/step - loss: 1.0906\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - ETA: 0s - loss: 0.147 - 18s 3ms/step - loss: 0.1476\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.0904\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.0777\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.0774\n",
      "5470/5470 [==============================] - 10s 2ms/step - loss: 0.0324\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.0310\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 22s 3ms/step - loss: 0.8085\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0900\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0611\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0635\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0591\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 0.0299\n",
      "2376/2376 [==============================] - 4s 1ms/step - loss: 0.0324\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 22s 3ms/step - loss: 0.8792\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.1207\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0944: 1s - l - ETA: 1s - - ETA: 0s - lo\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 26s 5ms/step - loss: 0.0871\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0735\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 0.0374\n",
      "2376/2376 [==============================] - 4s 1ms/step - loss: 0.0404\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 25s 3ms/step - loss: 0.9917\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.1570\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 0.1078\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0978\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0862\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 0.0340\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.0318\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 22s 3ms/step - loss: 1.0616\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.2376\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.1396\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.1216\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.1095A: 0s - loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5470/5470 [==============================] - 9s 1ms/step - loss: 0.0376\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0374\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 21s 3ms/step - loss: 0.8618\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0878: 1s - l\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0657\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0623\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0633\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 0.0299\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.0322A: 0s - \n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 22s 3ms/step - loss: 0.9111\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0998\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0831\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0633\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0647\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 0.0296\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0321\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 22s 3ms/step - loss: 1.0340\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.1424\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.1001\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.0688\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 21s 4ms/step - loss: 0.0730\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 0.0311\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0302\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 22s 3ms/step - loss: 0.9987\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 0.1591: 0s\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 21s 4ms/step - loss: 0.1028\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0899\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 0.0949\n",
      "5470/5470 [==============================] - 10s 2ms/step - loss: 0.0312\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.0323\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 24s 4ms/step - loss: 0.9148\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 0.0801\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0591\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0528\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 0.0539\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 0.0310\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.0309A: 0s\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 28s 4ms/step - loss: 0.9533\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.1076\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 0.0709\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 0.0606\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 0.0675\n",
      "5470/5470 [==============================] - 10s 2ms/step - loss: 0.0301\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.0314\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 23s 4ms/step - loss: 1.0061\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 21s 4ms/step - loss: 0.1256\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 21s 4ms/step - loss: 0.0863\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 0.0687\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0714\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 0.0322\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.0322\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 26s 4ms/step - loss: 1.1015\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.1695\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.1079\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0874\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 0.0784\n",
      "5470/5470 [==============================] - 10s 2ms/step - loss: 0.0338\n",
      "2376/2376 [==============================] - 4s 1ms/step - loss: 0.0348\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 29s 4ms/step - loss: 0.9418\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 0.0812\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 21s 4ms/step - loss: 0.0621\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0575\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0498\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 0.0308\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0303\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 22s 3ms/step - loss: 0.9738\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.0951\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0785\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 24s 4ms/step - loss: 0.0584\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0583\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 0.0300\n",
      "2376/2376 [==============================] - 4s 1ms/step - loss: 0.0297\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 23s 4ms/step - loss: 1.0601\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 0.1245\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 21s 4ms/step - loss: 0.0763\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 21s 4ms/step - loss: 0.0714\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 0.0689\n",
      "5470/5470 [==============================] - 10s 2ms/step - loss: 0.0358\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.0339\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 25s 4ms/step - loss: 1.1246\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 0.1523\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 0.0911\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0850\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 0.0732\n",
      "5470/5470 [==============================] - 9s 2ms/step - loss: 0.0315\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.0342\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0106\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0094\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0097\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 1.0101\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 1.0143\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 1.0035\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 1.0157\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0126\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 1.0066\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 1.0087\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 1.0136\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 1.0112\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 1.0000A: 0s - loss: 0\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.9907\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0116\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 1.0074\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 1.0086\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 1.0076\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 1.0110\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 1.0709\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.9621\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 20s 3ms/step - loss: 1.0108\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0127\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 1.0106\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0146\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 1.0118\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 1.0586\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 1.1391\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0090: 0s - los\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 1.0054\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0057\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0146\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 1.0123\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 1.0038\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.9711\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0105\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 1.0111\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0120\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 1.0106\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0079\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 1.0001\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.9933\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0085\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0112\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 1.0119\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 1.0086\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 1.0072\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 1.0016\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.9771\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 23s 3ms/step - loss: 1.0083\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 1.0081\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0098\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0111\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0060: \n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 1.0209\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.9574\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 22s 3ms/step - loss: 1.0117\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 1.0126\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0078\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0071\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 21s 4ms/step - loss: 1.0011\n",
      "5470/5470 [==============================] - 9s 2ms/step - loss: 1.0188\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.9581\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 22s 3ms/step - loss: 1.0083\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 21s 4ms/step - loss: 1.0147\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 1.0118\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 1.0080\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 1.0108\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 1.0178\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 1.0578\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 23s 4ms/step - loss: 1.0066\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 1.0098\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0113\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0110\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0116\n",
      "5470/5470 [==============================] - 10s 2ms/step - loss: 1.0058\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.9679\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 23s 3ms/step - loss: 1.0095\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0110\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0081\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0070\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0106\n",
      "5470/5470 [==============================] - 11s 2ms/step - loss: 1.0069\n",
      "2376/2376 [==============================] - 5s 2ms/step - loss: 1.0280\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 23s 4ms/step - loss: 1.0090\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0104\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 1.0127\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 1.0103\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 1.0063\n",
      "5470/5470 [==============================] - 11s 2ms/step - loss: 1.0219\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 1.0672\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 24s 4ms/step - loss: 1.0127\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0120\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0134\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 21s 4ms/step - loss: 1.0087\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0121\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 1.0008\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 1.0013\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 20s 3ms/step - loss: 1.0106\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 1.0112\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 1.0108\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 1.0074\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 1.0127\n",
      "5470/5470 [==============================] - 9s 2ms/step - loss: 1.0014\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 1.0057\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 22s 3ms/step - loss: 1.0143\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 21s 4ms/step - loss: 1.0110\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 1.0062\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 21s 4ms/step - loss: 1.0062\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 21s 4ms/step - loss: 1.0083\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 1.0063\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.9671\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0097\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 1.0106\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 15s 3ms/step - loss: 1.0123\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0099\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0104\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 1.0002A:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.9854\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 23s 3ms/step - loss: 1.0124\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 1.0111\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0091\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 1.0170\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0124\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 1.0763\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.9638\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 27s 3ms/step - loss: 1.0123\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 1.0151\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0091\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0078\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0102\n",
      "5470/5470 [==============================] - 11s 2ms/step - loss: 1.0268\n",
      "2376/2376 [==============================] - 5s 2ms/step - loss: 0.9562\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 23s 3ms/step - loss: 1.0092: 2s\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0050\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0130\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 1.0092\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 1.0112\n",
      "5470/5470 [==============================] - 11s 2ms/step - loss: 1.0878\n",
      "2376/2376 [==============================] - 5s 2ms/step - loss: 1.1885\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 25s 4ms/step - loss: 1.0082\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 1.0130\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 1.0124\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0071\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0107\n",
      "5470/5470 [==============================] - 10s 2ms/step - loss: 1.0085\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 1.0332\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 23s 3ms/step - loss: 1.0113\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0137\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 1.0072\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0085\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 1.0085\n",
      "5470/5470 [==============================] - 10s 2ms/step - loss: 1.0002\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.9952\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 25s 4ms/step - loss: 1.0104\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 1.0080\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 1.0075\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 1.0104\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0122\n",
      "5470/5470 [==============================] - 10s 2ms/step - loss: 1.0101\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 1.0380\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 22s 3ms/step - loss: 1.0121\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 1.0119\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0069\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0121\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 1.0107\n",
      "5470/5470 [==============================] - 10s 2ms/step - loss: 1.0000\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.9891A: 0s - los\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 21s 3ms/step - loss: 1.0090\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0030\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0104\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 1.0036\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 1.0139\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 1.0096\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 1.0365\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 21s 3ms/step - loss: 1.0113\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0104\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0083\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 1.0106\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 1.0128\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 1.0518\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.9574\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 20s 3ms/step - loss: 1.0090\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 1.0103\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 1.0102\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 21s 4ms/step - loss: 1.0111\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0111\n",
      "5470/5470 [==============================] - 9s 2ms/step - loss: 1.0065\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 1.0269A - ETA: 0s \n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 21s 3ms/step - loss: 1.0091\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0113\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 1.0102\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0086\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 1.0107\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 1.0037\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.9714\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 21s 3ms/step - loss: 1.0090\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 21s 4ms/step - loss: 1.0101\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0128\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0033\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0094\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 1.0082\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 1.0323\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 24s 3ms/step - loss: 1.0107\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0106\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0096\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0102\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0069\n",
      "5470/5470 [==============================] - 10s 2ms/step - loss: 1.0000\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.9908\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 20s 3ms/step - loss: 1.0093\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0115\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 1.0108\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0093\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0097\n",
      "5470/5470 [==============================] - 9s 2ms/step - loss: 1.0012\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.9788\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 20s 3ms/step - loss: 1.0108\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0133\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 1.0120\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0131\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0132\n",
      "5470/5470 [==============================] - 10s 2ms/step - loss: 1.0000\n",
      "2376/2376 [==============================] - 4s 1ms/step - loss: 0.9886\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 21s 3ms/step - loss: 1.0105\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0093\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0103\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 1.0061\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0095\n",
      "5470/5470 [==============================] - 9s 2ms/step - loss: 1.0048\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.9693\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 24s 4ms/step - loss: 1.0133\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 1.0114\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0111\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 1.0073\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0103\n",
      "5470/5470 [==============================] - 10s 2ms/step - loss: 1.0021\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 1.0097\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 22s 3ms/step - loss: 1.0132\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0133\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0119\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 1.0125\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0134\n",
      "5470/5470 [==============================] - 12s 2ms/step - loss: 1.0178\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 1.0577\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 22s 3ms/step - loss: 1.0089\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0140\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0096\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0106\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0112\n",
      "5470/5470 [==============================] - 9s 2ms/step - loss: 1.0002\n",
      "2376/2376 [==============================] - 4s 1ms/step - loss: 0.9857A: 0s - loss:\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 22s 3ms/step - loss: 1.0101\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 1.0109\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0102\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 1.0102\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 1.0086: 0s -\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 1.0001\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.9869\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 24s 4ms/step - loss: 1.0085\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 1.0093\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0093\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0103\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 1.0070\n",
      "5470/5470 [==============================] - 10s 2ms/step - loss: 1.0014\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 1.0059\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 22s 3ms/step - loss: 1.0109\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0095\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 1.0127\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0070\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0069\n",
      "5470/5470 [==============================] - 11s 2ms/step - loss: 1.0036\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.9717\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 24s 4ms/step - loss: 1.0136\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 1.0099\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 1.0137\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0117\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0112\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 1.0166\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 1.0550A: 0s - loss: 1.0\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 24s 3ms/step - loss: 1.0090\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 1.0088\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0092\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 1.0073\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 1.0116\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 1.0015\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.9776\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 20s 3ms/step - loss: 1.0123\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 1.0092\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 1.0129\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 1.0121\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 16s 3ms/step - loss: 1.0104\n",
      "5470/5470 [==============================] - 9s 2ms/step - loss: 1.0005\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.9826\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 25s 4ms/step - loss: 1.0075\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0136\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0094\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0081\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0050:\n",
      "5470/5470 [==============================] - 10s 2ms/step - loss: 1.0067\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.9666\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 23s 3ms/step - loss: 1.0090\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 1.0117\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 23s 4ms/step - loss: 1.0112\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 22s 4ms/step - loss: 1.0120\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 22s 4ms/step - loss: 1.0115\n",
      "5470/5470 [==============================] - 8s 1ms/step - loss: 1.0022\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 1.0103\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 21s 3ms/step - loss: 1.0113\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0102\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0090\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0097\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 1.0083\n",
      "5470/5470 [==============================] - 9s 2ms/step - loss: 1.0002\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.9957\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 22s 3ms/step - loss: 1.0097\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 1.0108\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0098\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0133\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 28s 5ms/step - loss: 1.0096\n",
      "5470/5470 [==============================] - 13s 2ms/step - loss: 1.0050\n",
      "2376/2376 [==============================] - 6s 2ms/step - loss: 1.0218\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5470/5470 [==============================] - 23s 4ms/step - loss: 1.0132\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 23s 4ms/step - loss: 1.0124\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0101\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0108\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 1.0086\n",
      "5470/5470 [==============================] - 13s 2ms/step - loss: 1.0056\n",
      "2376/2376 [==============================] - 5s 2ms/step - loss: 1.0237\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 26s 4ms/step - loss: 1.0077\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 21s 4ms/step - loss: 1.0080\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 22s 4ms/step - loss: 1.0135\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 22s 4ms/step - loss: 1.0090\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 24s 4ms/step - loss: 1.0100\n",
      "5470/5470 [==============================] - 14s 2ms/step - loss: 1.0003: 0s - loss\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.9847\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 23s 4ms/step - loss: 1.0105\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0109\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 1.0113\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 25s 5ms/step - loss: 1.0104\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 23s 4ms/step - loss: 1.0125\n",
      "5470/5470 [==============================] - 11s 2ms/step - loss: 1.0000\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.9887\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 28s 4ms/step - loss: 1.0078\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0093\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0102\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 21s 4ms/step - loss: 1.0087\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 1.0107\n",
      "5470/5470 [==============================] - 10s 2ms/step - loss: 1.0023\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.9747\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 23s 3ms/step - loss: 1.0114\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0102\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0113\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0103\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 1.0071\n",
      "5470/5470 [==============================] - 10s 2ms/step - loss: 1.0168\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.9589\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 27s 3ms/step - loss: 1.0092\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 21s 4ms/step - loss: 1.0111\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 23s 4ms/step - loss: 1.0133\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0159\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0083\n",
      "5470/5470 [==============================] - 11s 2ms/step - loss: 1.0101\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.9630\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 22s 3ms/step - loss: 1.0092\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 23s 4ms/step - loss: 1.0112: 0s - loss: 1.011\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 1.0131\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0141\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0117\n",
      "5470/5470 [==============================] - 11s 2ms/step - loss: 1.0162\n",
      "2376/2376 [==============================] - 5s 2ms/step - loss: 1.0540\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 22s 3ms/step - loss: 1.0077\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 1.0119\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 21s 4ms/step - loss: 1.0122\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 1.0078\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 1.0093\n",
      "5470/5470 [==============================] - 10s 2ms/step - loss: 1.0066\n",
      "2376/2376 [==============================] - 4s 1ms/step - loss: 1.0269A: 0s - loss: 1.028\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 23s 4ms/step - loss: 1.0101\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0100\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 21s 4ms/step - loss: 1.0079\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0135\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0102\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 1.0015\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.9778\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 22s 3ms/step - loss: 1.0100\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0114\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 21s 4ms/step - loss: 1.0087\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0126\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0103\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 1.0288\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.9559\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 23s 4ms/step - loss: 1.0036\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 21s 4ms/step - loss: 1.0109\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 1.0099\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0122\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 1.0077\n",
      "5470/5470 [==============================] - 9s 2ms/step - loss: 1.0001\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.9939\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 21s 3ms/step - loss: 1.0100\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0080\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0129\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0111\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 17s 3ms/step - loss: 1.0111\n",
      "5470/5470 [==============================] - 9s 1ms/step - loss: 1.0001\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.9876\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 21s 3ms/step - loss: 1.0092\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0111\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 24s 4ms/step - loss: 1.0113\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 28s 5ms/step - loss: 1.0083\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 21s 4ms/step - loss: 1.0113\n",
      "5470/5470 [==============================] - 10s 2ms/step - loss: 1.0001\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.9879\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 22s 3ms/step - loss: 1.0114\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0108\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0133\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 20s 4ms/step - loss: 1.0074\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 19s 3ms/step - loss: 1.0076\n",
      "5470/5470 [==============================] - 10s 2ms/step - loss: 1.0068\n",
      "2376/2376 [==============================] - 3s 1ms/step - loss: 0.9664\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 25s 4ms/step - loss: 1.0103\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 19s 4ms/step - loss: 1.0124\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 18s 3ms/step - loss: 1.0096\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 21s 4ms/step - loss: 1.0072\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 21s 4ms/step - loss: 1.0120\n",
      "5470/5470 [==============================] - 10s 2ms/step - loss: 1.0039\n",
      "2376/2376 [==============================] - 4s 2ms/step - loss: 0.9710\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 38s 6ms/step - loss: 1.0123\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 28s 5ms/step - loss: 1.0114\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 26s 5ms/step - loss: 1.0118\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 26s 5ms/step - loss: 1.0110\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 27s 5ms/step - loss: 1.0126\n",
      "5470/5470 [==============================] - 14s 2ms/step - loss: 1.0324\n",
      "2376/2376 [==============================] - 5s 2ms/step - loss: 0.9557\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 36s 5ms/step - loss: 1.0122\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 34s 6ms/step - loss: 1.0094\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 25s 5ms/step - loss: 1.0103\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 34s 6ms/step - loss: 1.0149\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 28s 5ms/step - loss: 1.0128\n",
      "5470/5470 [==============================] - 13s 2ms/step - loss: 1.0412\n",
      "2376/2376 [==============================] - 5s 2ms/step - loss: 0.9559A: 0s - loss: 0.\n",
      "Epoch 1/5\n",
      "5470/5470 [==============================] - 31s 5ms/step - loss: 1.0129\n",
      "Epoch 2/5\n",
      "5470/5470 [==============================] - 27s 5ms/step - loss: 1.0075\n",
      "Epoch 3/5\n",
      "5470/5470 [==============================] - 27s 5ms/step - loss: 1.0098\n",
      "Epoch 4/5\n",
      "5470/5470 [==============================] - 28s 5ms/step - loss: 1.0128\n",
      "Epoch 5/5\n",
      "5470/5470 [==============================] - 26s 5ms/step - loss: 1.0085\n",
      "5470/5470 [==============================] - 13s 2ms/step - loss: 1.0148: 0s - loss: 1. - ETA: 0s - loss\n",
      "2376/2376 [==============================] - 5s 2ms/step - loss: 1.0505\n"
     ]
    }
   ],
   "source": [
    "# runs for around 4 hours! avoid running if possible!!!!\n",
    "\n",
    "# define min_loss\n",
    "min_loss = math.inf\n",
    "\n",
    "# define best hyper params to use\n",
    "best_func = None\n",
    "best_first_hidden_nodes = None\n",
    "best_second_hidden_nodes = None\n",
    "best_dropout = None\n",
    "\n",
    "for activation_func in activation_funcs:\n",
    "    for i in range(len(node_values)):\n",
    "        for j in range(len(node_values)):\n",
    "            for drop_value in drop_values:\n",
    "                \n",
    "                # define an LSTM for the normalized training data\n",
    "                cross_valid_model = Sequential()\n",
    "                # input_shape for each data input is window_size x number of features (column) in training_data\n",
    "                cross_valid_model.add(\n",
    "                    LSTM(\n",
    "                        node_values[i],\n",
    "                        activation=activation_func,\n",
    "                        input_shape=(window_size, 11),\n",
    "                        return_sequences=True\n",
    "                    )\n",
    "                )\n",
    "                cross_valid_model.add(\n",
    "                    LSTM(\n",
    "                        node_values[j],\n",
    "                        activation=activation_func,\n",
    "                        return_sequences=False\n",
    "                    )\n",
    "                )\n",
    "                cross_valid_model.add(Dropout(drop_value))\n",
    "\n",
    "                # output either standardized 0 or 1\n",
    "                cross_valid_model.add(Dense(1))\n",
    "\n",
    "                # leaving optimizer and loss funcs as-is\n",
    "                cross_valid_model.compile(optimizer='SGD', loss='mse')\n",
    "                \n",
    "                # fit data to the cross_validation model\n",
    "                cross_valid_model.fit(training_ts_generator, epochs=5)\n",
    "                \n",
    "                # training/testing loss values\n",
    "                cross_valid_train_loss = cross_valid_model.evaluate(training_ts_generator)\n",
    "                cross_valid_test_loss = cross_valid_model.evaluate(testing_ts_generator)\n",
    "                \n",
    "                if cross_valid_test_loss < min_loss:\n",
    "                    best_func = activation_func\n",
    "                    best_first_hidden_nodes = node_values[i]\n",
    "                    best_second_hidden_nodes = node_values[j]\n",
    "                    best_dropout = drop_value\n",
    "                    min_loss = cross_valid_test_loss\n",
    "                    print(f'{best_func}, {best_first_hidden_nodes}, {best_second_hidden_nodes}, {best_dropout}')\n",
    "                    print(min_loss)\n",
    "                \n",
    "# cross_valid_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid\n",
      "64\n",
      "96\n",
      "0.2\n",
      "0.02916168048977852\n"
     ]
    }
   ],
   "source": [
    "print(best_func)\n",
    "print(best_first_hidden_nodes)\n",
    "print(best_second_hidden_nodes)\n",
    "print(best_dropout)\n",
    "print(min_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
